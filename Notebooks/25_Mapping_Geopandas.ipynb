{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Data Science\n",
    "\n",
    "### Data Science Tasks: Geographical and Spatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo npm cache clean -f\n",
    "#!sudo npm install -g n\n",
    "#!sudo n latest\n",
    "#!sudo apt-get install --reinstall nodejs-legacy\n",
    "# ! pip install plotly-geo geopandas shapely pyshp html5lib\n",
    "#! jupyter labextension install jupyterlab-plotly@4.7.1\n",
    "#! jupyter labextension install @jupyter-widgets/jupyterlab-manager plotlywidget@4.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in /usr/lib/python3/dist-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests) (2.8)\n",
      "Installing collected packages: requests\n",
      "Successfully installed requests-2.25.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install python-twitter\n",
    "\n",
    "import pip\n",
    "pip.main(['install', '-U', 'requests'])\n",
    "#pip.main(['install','nominatim'])\n",
    "#pip.main(['install','geopy'])\n",
    "#pip.main(['install','pydotplus'])\n",
    "#pip.main(['install','python-twitter'])\n",
    "#pip.main(['install','python-levenshtein'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'module' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-772688fdce0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtwitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/twitter/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m )\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mApi\u001b[0m                        \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/twitter/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrequests_oauthlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOAuth1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOAuth2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests_oauthlib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m\"2.0.0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     msg = (\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m\"You are using requests version %s, which is older than \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'module' and 'str'"
     ]
    }
   ],
   "source": [
    "# ! pip install plotly-geo geopandas shapely pyshp html5lib\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import twitter\n",
    "import nltk\n",
    "import re\n",
    "import networkx as nx\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import webbrowser\n",
    "import codecs\n",
    "import Levenshtein\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from itertools import chain\n",
    "from itertools import cycle\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nominatim import Nominatim\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import geopy.geocoders as gg\n",
    "\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.express as px\n",
    "#import plotly.figure_factory as ff\n",
    "\n",
    "from IPython.display import Image, HTML, IFrame, FileLink, FileLinks #needed to render in notebook\n",
    "from IPython.core.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pydotplus #Install http://www.graphviz.org/ & Instal https://pypi.python.org/pypi/pydotplus\n",
    "\n",
    "%matplotlib inline\n",
    "# Set default figure size for this notebook\n",
    "plt.rcParams['figure.figsize'] = (16.0, 12.8)\n",
    "#plt.switch_backend('Agg')\n",
    "\n",
    "py.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying the path to the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = \"../templates/\"\n",
    "outputs = \"../outputs/\"\n",
    "\n",
    "dotfile = \"graph_retweet.dot\"\n",
    "pngfile = \"graph_retweet.png\"\n",
    "protofile = \"graph_retweet.html\"\n",
    "tweetsfile = \"Tweets_dump.txt\"\n",
    "template_proto = 'template_protoviz.html'\n",
    "\n",
    "pathdotfile = os.path.join(outputs,dotfile)\n",
    "pathpngfile = os.path.join(outputs,pngfile)\n",
    "pathprotofile = os.path.join(outputs,protofile)\n",
    "pathtweetsfile = os.path.join(outputs,tweetsfile)\n",
    "pathtemplate = os.path.join(templates,template_proto)\n",
    "\n",
    "stoplist_en = nltk.corpus.stopwords.words('english')\n",
    "stoplist_pt = nltk.corpus.stopwords.words('portuguese')\n",
    "ignorewords = stoplist_en + stoplist_pt + ['',' ','-','rt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using geographical resources within Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pypi.python.org/pypi/geopy  \n",
    "#https://www.mapsmarker.com/kb/user-guide/how-mapquest-api/\n",
    "#https://geopy.readthedocs.io/en/stable/#openmapquest\n",
    "\n",
    "#geolocator = gg.OpenMapQuest(api_key=OMQapikey)\n",
    "#geolocator = gg.GoogleV3()\n",
    "\n",
    "geolocator = gg.Nominatim(user_agent=\"test_application\") #https://operations.osmfoundation.org/policies/nominatim/\n",
    "#location = geolocator.reverse(\"52.509669, 13.376294\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To geolocate a query to an address and coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rua Dona Mariana, Botafogo, Zona Sul do Rio de Janeiro, Rio de Janeiro, Região Geográfica Imediata do Rio de Janeiro, Região Metropolitana do Rio de Janeiro, Região Geográfica Intermediária do Rio de Janeiro, Rio de Janeiro, Região Sudeste, 22280-020, Brasil\n",
      "(-22.9530169, -43.1885829)\n",
      "{'place_id': 84902582, 'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright', 'osm_type': 'way', 'osm_id': 14519270, 'boundingbox': ['-22.9566891', '-22.9497369', '-43.1896942', '-43.1872597'], 'lat': '-22.9530169', 'lon': '-43.1885829', 'display_name': 'Rua Dona Mariana, Botafogo, Zona Sul do Rio de Janeiro, Rio de Janeiro, Região Geográfica Imediata do Rio de Janeiro, Região Metropolitana do Rio de Janeiro, Região Geográfica Intermediária do Rio de Janeiro, Rio de Janeiro, Região Sudeste, 22280-020, Brasil', 'class': 'highway', 'type': 'residential', 'importance': 0.41000000000000003}\n"
     ]
    }
   ],
   "source": [
    "logradouro = \"Dona Mariana, Botafogo\"\n",
    "location = geolocator.geocode(logradouro)\n",
    "print(location.address)\n",
    "address = location.address\n",
    "print((location.latitude, location.longitude))\n",
    "latitude, longitude = location.latitude, location.longitude\n",
    "print(location.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potsdamer Platz, Bellevuestraße, Botschaftsviertel, Tiergarten, Mitte, Berlin, 10785, Deutschland\n",
      "(52.5098014, 13.375589791291057)\n",
      "{'place_id': 235599123, 'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright', 'osm_type': 'relation', 'osm_id': 3200536, 'lat': '52.5098014', 'lon': '13.375589791291057', 'display_name': 'Potsdamer Platz, Bellevuestraße, Botschaftsviertel, Tiergarten, Mitte, Berlin, 10785, Deutschland', 'address': {'tourism': 'Potsdamer Platz', 'road': 'Bellevuestraße', 'quarter': 'Botschaftsviertel', 'suburb': 'Tiergarten', 'borough': 'Mitte', 'city': 'Berlin', 'postcode': '10785', 'country': 'Deutschland', 'country_code': 'de'}, 'boundingbox': ['52.5082999', '52.5100374', '13.3750548', '13.3769528']}\n"
     ]
    }
   ],
   "source": [
    "location = geolocator.reverse('52.509669, 13.376294')\n",
    "print(location.address)\n",
    "print((location.latitude, location.longitude))\n",
    "print(location.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7755102040816326"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Measuring editing distances between names:\n",
    "Levenshtein.ratio('Dona Mariano, Botafoga', 'Rua Dona Mariana - Botafogo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800px\"\n",
       "            height=\"600px\"\n",
       "            src=\"http://maps.google.com/maps?q=Rua Dona Mariana, Botafogo, Zona Sul do Rio de Janeiro, Rio de Janeiro, Região Geográfica Imediata do Rio de Janeiro, Região Metropolitana do Rio de Janeiro, Região Geográfica Intermediária do Rio de Janeiro, Rio de Janeiro, Região Sudeste, 22280-020, Brasil&loc:-22.9530169+-43.1885829&z=17&t=k&output=embed\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f49b07edb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://developers.google.com/maps/documentation/staticmaps/\n",
    "#http://stackoverflow.com/questions/2660201/what-parameters-should-i-use-in-a-google-maps-url-to-go-to-a-lat-lon/9919251#9919251\n",
    "#m – normal map k – satellite h – hybrid p – terrain\n",
    "\n",
    "def gmap(address,lat,lon,zoom=15,tmap='m'):\n",
    "    # Google Maps URL template for an iframe\n",
    "    google_maps_url = 'http://maps.google.com/maps?q={0}&loc:{1}+{2}&z={3}&t={4}&output=embed'.format(address,\n",
    "                                                                                                     lat,\n",
    "                                                                                                     lon,\n",
    "                                                                                                     zoom,\n",
    "                                                                                                     tmap,)\n",
    "    display(IFrame(google_maps_url, '800px', '600px'))\n",
    "    \n",
    "gmap(address, latitude, longitude,17,'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the address corresponding to a set of coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anexo 2 do Senado Federal, N2, Setor de Autarquias Sul, Asa Norte, Plano Piloto, Região Geográfica Imediata do Distrito Federal, Região Integrada de Desenvolvimento do Distrito Federal e Entorno, Região Geográfica Intermediária do Distrito Federal, Distrito Federal, Região Centro-Oeste, 70040906, Brasil\n",
      "(-15.798067249999999, -47.864397090465545)\n"
     ]
    }
   ],
   "source": [
    "addresses = geolocator.reverse('-15.798,-47.865')\n",
    "for address in addresses:\n",
    "    print(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Plotly\n",
    "inspired by [this](https://towardsdatascience.com/an-introduction-to-geographical-data-visualization-3486959cd4b8) post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict (\n",
    "    type = 'choropleth',\n",
    "    locations = ['China','Canada','Brazil'],\n",
    "    locationmode='country names',\n",
    "    #colorscale = ['Viridis'],\n",
    "    z=[10,20,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outmap = go.Figure(data=[data])\n",
    "py.offline.plot(outmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using data on [World Hapiness](https://www.kaggle.com/unsdsn/world-happiness#2017.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/CSVs/happiness2017.csv')\n",
    "\n",
    "data = dict (\n",
    "    type = 'choropleth',\n",
    "    locations = df['Country'],\n",
    "    locationmode='country names',\n",
    "    #colorscale = ['Viridis'],\n",
    "    z=df['Happiness.Score'])\n",
    "\n",
    "outmap = go.Figure(data=[data])\n",
    "py.offline.plot(outmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using data on [US Employment](https://raw.githubusercontent.com/plotly/datasets/master/laucnty16.csv) following [these](https://plotly.github.io/plotly.py-docs/generated/plotly.express.choropleth.html) and [these instructions](https://plotly.com/python/choropleth-maps/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/fips-unemp-16.csv\",\n",
    "                   dtype={\"fips\": str})\n",
    "\n",
    "fig = px.choropleth(df, \n",
    "                    geojson=counties, \n",
    "                    locations='fips', \n",
    "                    color='unemp',\n",
    "                    color_continuous_scale=\"Viridis\",\n",
    "                    range_color=(0, 12),\n",
    "                    scope=\"usa\",\n",
    "                    labels={'unemp':'unemployment rate'}\n",
    "                    )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "py.offline.plot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Python and QGIS for geospatial visualizations - a Case Study  \n",
    "https://www.airpair.com/python/posts/using-python-and-qgis-for-geospatial-visualization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://www.nuforc.org/webreports/\"\n",
    "index_url = \"http://www.nuforc.org/webreports/ndxevent.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_cast_as_dt(dateStr, fmt):\n",
    "    try:\n",
    "        datetime.strptime(dateStr, fmt)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def parse_dt(dateStr):\n",
    "    # the data in the website comes in two different formats, try both \n",
    "    for fmt in [\"%m/%d/%y %H:%M\", \"%m/%d/%y\"]:\n",
    "        try:\n",
    "            return datetime.strptime(dateStr, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "def get_data_from_url(url):\n",
    "    print(\"Processing {}\".format(url))\n",
    "    data = []\n",
    "    source = BeautifulSoup(urllib.request.urlopen(url), \"html5lib\")\n",
    "    for row in source('tr'):\n",
    "        if not row('td'):\n",
    "            continue # header row\n",
    "        row_data = row('td')\n",
    "        # parse the datetime from the string\n",
    "        date_time = parse_dt(row_data[0].text)\n",
    "        city = row_data[1].text\n",
    "        state = row_data[2].text\n",
    "        shape = row_data[3].text\n",
    "        duration = row_data[4].text\n",
    "        data.append((date_time, city, state, shape, duration))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing http://www.nuforc.org/webreports/ndxe202005.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe202004.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe202003.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe202002.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe202001.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201912.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201911.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201910.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201909.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201908.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201907.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201906.html\n"
     ]
    }
   ],
   "source": [
    "# get the index page\n",
    "raw_page = urllib.request.urlopen(index_url)\n",
    "source = BeautifulSoup(raw_page, \"html5lib\")\n",
    "# get all the links in the index page\n",
    "func1 = lambda x: (x.text, base_url + x['href'])\n",
    "monthly_urls = list(map(func1,source('a')))\n",
    "# get  the last 12 links that have a text like mm/yyyy\n",
    "func2 = lambda x: can_cast_as_dt(x[0], \"%m/%Y\")\n",
    "last_year_urls = filter(func2, monthly_urls[0:13]) \n",
    "# extract the data from each monthly page and flatten the lists of tuples\n",
    "last_year_ufos = list(chain(*map(lambda x: get_data_from_url(x[1]), last_year_urls)))\n",
    "# initialize a pandas DataFrame with the list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufos_df = pd.DataFrame(last_year_ufos, columns=[\"start\",\"city\",\"state\",\"shape\",\"duration_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-15 19:25:00</td>\n",
       "      <td>Indore City (India)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>60 seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-14 21:40:00</td>\n",
       "      <td>Wellborn</td>\n",
       "      <td>FL</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>5 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-14 20:45:00</td>\n",
       "      <td>Black River Falls</td>\n",
       "      <td>WI</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>2 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-14 18:45:00</td>\n",
       "      <td>Sale (Australia)</td>\n",
       "      <td></td>\n",
       "      <td>Light</td>\n",
       "      <td>10min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-14 03:30:00</td>\n",
       "      <td>Nooksack</td>\n",
       "      <td>WA</td>\n",
       "      <td>Light</td>\n",
       "      <td>5 minutes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                start                 city state     shape  \\\n",
       "0 2020-05-15 19:25:00  Indore City (India)                   \n",
       "1 2020-05-14 21:40:00             Wellborn    FL  Triangle   \n",
       "2 2020-05-14 20:45:00    Black River Falls    WI  Triangle   \n",
       "3 2020-05-14 18:45:00     Sale (Australia)           Light   \n",
       "4 2020-05-14 03:30:00             Nooksack    WA     Light   \n",
       "\n",
       "  duration_description  \n",
       "0           60 seconds  \n",
       "1            5 minutes  \n",
       "2            2 minutes  \n",
       "3                10min  \n",
       "4            5 minutes  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufos_df.replace(to_replace='', value=np.nan, inplace=True, limit=None, regex=False, method='pad')\n",
    "ufos_df = ufos_df.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-14 21:40:00</td>\n",
       "      <td>Wellborn</td>\n",
       "      <td>FL</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>5 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-14 20:45:00</td>\n",
       "      <td>Black River Falls</td>\n",
       "      <td>WI</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>2 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-14 03:30:00</td>\n",
       "      <td>Nooksack</td>\n",
       "      <td>WA</td>\n",
       "      <td>Light</td>\n",
       "      <td>5 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-05-14 01:59:00</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Circle</td>\n",
       "      <td>1.5 seconds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-05-14 00:20:00</td>\n",
       "      <td>Charleston (James Island)</td>\n",
       "      <td>SC</td>\n",
       "      <td>Fireball</td>\n",
       "      <td>5s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                start                       city state     shape  \\\n",
       "1 2020-05-14 21:40:00                   Wellborn    FL  Triangle   \n",
       "2 2020-05-14 20:45:00          Black River Falls    WI  Triangle   \n",
       "4 2020-05-14 03:30:00                   Nooksack    WA     Light   \n",
       "5 2020-05-14 01:59:00                      Tempe    AZ    Circle   \n",
       "6 2020-05-14 00:20:00  Charleston (James Island)    SC  Fireball   \n",
       "\n",
       "  duration_description  \n",
       "1            5 minutes  \n",
       "2            2 minutes  \n",
       "4            5 minutes  \n",
       "5          1.5 seconds  \n",
       "6                   5s  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufos_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that infers the duration from the text \n",
    "def infer_duration_in_seconds(text):\n",
    "    # try different regexps to extract the total seconds\n",
    "    text = text.replace('<','')\n",
    "    text = text.replace('>','')\n",
    "    text = text.replace('?','')\n",
    "    text = text.replace('+','')\n",
    "    text = text.replace('~','')\n",
    "    metric_text = [\"second\",\"s\",\"Second\",\"segundo\",\"minute\",\"m\",\"min\",\"Minute\",\"hour\",\"h\",\"Hour\",'Currently']\n",
    "    metric_seconds = [1,1,1,1,60,60,60,3600,3600,3600,10]\n",
    "    for metric,mult in zip(metric_text, metric_seconds):\n",
    "        regex = \"\\s*(\\d+)\\+?\\s*{}s?\".format(metric)\n",
    "        res = re.findall(regex,text)\n",
    "        if len(res)>0:\n",
    "            return int(float(res[0]) * mult)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the duration in seconds\n",
    "ufos_df[\"duration_secs\"] = ufos_df[\"duration_description\"].apply(infer_duration_in_seconds)\n",
    "\n",
    "# now we can infer the end time of the UFO sighting as well\n",
    "# which will be useful for the animation later\n",
    "ufos_df[\"end\"] = ufos_df.apply(lambda x:x[\"start\"] + timedelta(seconds=x[\"duration_secs\"]),axis=1)\n",
    "ufos_df = ufos_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration_description</th>\n",
       "      <th>duration_secs</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-14 21:40:00</td>\n",
       "      <td>Wellborn</td>\n",
       "      <td>FL</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-05-14 21:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-14 20:45:00</td>\n",
       "      <td>Black River Falls</td>\n",
       "      <td>WI</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>120</td>\n",
       "      <td>2020-05-14 20:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-14 03:30:00</td>\n",
       "      <td>Nooksack</td>\n",
       "      <td>WA</td>\n",
       "      <td>Light</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-05-14 03:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-05-14 01:59:00</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Circle</td>\n",
       "      <td>1.5 seconds</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-14 01:59:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-05-14 00:20:00</td>\n",
       "      <td>Charleston (James Island)</td>\n",
       "      <td>SC</td>\n",
       "      <td>Fireball</td>\n",
       "      <td>5s</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-14 00:20:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                start                       city state     shape  \\\n",
       "1 2020-05-14 21:40:00                   Wellborn    FL  Triangle   \n",
       "2 2020-05-14 20:45:00          Black River Falls    WI  Triangle   \n",
       "4 2020-05-14 03:30:00                   Nooksack    WA     Light   \n",
       "5 2020-05-14 01:59:00                      Tempe    AZ    Circle   \n",
       "6 2020-05-14 00:20:00  Charleston (James Island)    SC  Fireball   \n",
       "\n",
       "  duration_description  duration_secs                 end  \n",
       "1            5 minutes            300 2020-05-14 21:45:00  \n",
       "2            2 minutes            120 2020-05-14 20:47:00  \n",
       "4            5 minutes            300 2020-05-14 03:35:00  \n",
       "5          1.5 seconds              5 2020-05-14 01:59:05  \n",
       "6                   5s              5 2020-05-14 00:20:05  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufos_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'place_id': 235467351,\n",
       "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright',\n",
       "  'osm_type': 'relation',\n",
       "  'osm_id': 206655,\n",
       "  'boundingbox': ['36.930691', '37.2206658', '-76.646093', '-76.36161'],\n",
       "  'lat': '36.9786449',\n",
       "  'lon': '-76.4321089',\n",
       "  'display_name': 'Newport News, Newport News City, Virginia, United States of America',\n",
       "  'class': 'boundary',\n",
       "  'type': 'administrative',\n",
       "  'importance': 0.686660556787456,\n",
       "  'icon': 'https://nominatim.openstreetmap.org/images/mapicons/poi_boundary_administrative.p.20.png'},\n",
       " {'place_id': 78017695,\n",
       "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright',\n",
       "  'osm_type': 'node',\n",
       "  'osm_id': 7022584310,\n",
       "  'boundingbox': ['37.0178211', '37.0278211', '-76.4568619', '-76.4468619'],\n",
       "  'lat': '37.0228211',\n",
       "  'lon': '-76.4518619',\n",
       "  'display_name': 'Newport News, Warwick Boulevard, Huntington Heights, Newport News, Newport News City, Virginia, 23601, United States of America',\n",
       "  'class': 'railway',\n",
       "  'type': 'station',\n",
       "  'importance': 0.49244155193061573,\n",
       "  'icon': 'https://nominatim.openstreetmap.org/images/mapicons/transport_train_station2.p.20.png'},\n",
       " {'place_id': 80180729,\n",
       "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright',\n",
       "  'osm_type': 'node',\n",
       "  'osm_id': 7022584309,\n",
       "  'boundingbox': ['37.0230356', '37.0231356', '-76.4519501', '-76.4518501'],\n",
       "  'lat': '37.0230856',\n",
       "  'lon': '-76.4519001',\n",
       "  'display_name': 'Newport News, South Avenue, Hilton Village, Newport News, Newport News City, Virginia, 23605, United States of America',\n",
       "  'class': 'railway',\n",
       "  'type': 'stop',\n",
       "  'importance': 0.201},\n",
       " {'place_id': 567706,\n",
       "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright',\n",
       "  'osm_type': 'node',\n",
       "  'osm_id': 221158656,\n",
       "  'boundingbox': ['37.02192', '37.02202', '-76.451263', '-76.451163'],\n",
       "  'lat': '37.02197',\n",
       "  'lon': '-76.451213',\n",
       "  'display_name': 'Newport News, Warwick Boulevard, Huntington Heights, Newport News, Newport News City, Virginia, 23608, United States of America',\n",
       "  'class': 'railway',\n",
       "  'type': 'stop',\n",
       "  'importance': 0.201},\n",
       " {'place_id': 71316293,\n",
       "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright',\n",
       "  'osm_type': 'node',\n",
       "  'osm_id': 6173044103,\n",
       "  'boundingbox': ['52.0855514', '52.0856514', '-0.7270735', '-0.7269735'],\n",
       "  'lat': '52.0856014',\n",
       "  'lon': '-0.7270235',\n",
       "  'display_name': 'Newport News, High Street, Newport Pagnell, Milton Keynes, South East, England, MK16 8EH, United Kingdom',\n",
       "  'class': 'shop',\n",
       "  'type': 'newsagent',\n",
       "  'importance': 0.201}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://wiki.openstreetmap.org/wiki/Nominatim_usage_policy\n",
    "# https://github.com/twain47/Nominatim/blob/master/docs/Installation.md\n",
    "geolocator = Nominatim()\n",
    "\n",
    "geolocator.query('Newport News')\n",
    "#geolocator.query(\"Houston, TX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Be careful with too many queries made to the server in a short period of time\n",
    "\n",
    "ufos_df[\"lat\"] = 0\n",
    "ufos_df[\"lon\"] = 0\n",
    "for i in range(len(ufos_df[0:10])):\n",
    "    try:\n",
    "        resp_json = geolocator.query(ufos_df['city'][i])\n",
    "        ufos_df[\"lat\"][i] = resp_json[0]['lat']\n",
    "        ufos_df[\"lon\"][i] = resp_json[0]['lon']\n",
    "    except:\n",
    "        ufos_df[\"lat\"][i] = 0\n",
    "        ufos_df[\"lat\"][i] = 0\n",
    "    time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration_description</th>\n",
       "      <th>duration_secs</th>\n",
       "      <th>end</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-14 21:40:00</td>\n",
       "      <td>Wellborn</td>\n",
       "      <td>FL</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-05-14 21:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>-85.8810774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-14 20:45:00</td>\n",
       "      <td>Black River Falls</td>\n",
       "      <td>WI</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>120</td>\n",
       "      <td>2020-05-14 20:47:00</td>\n",
       "      <td>0</td>\n",
       "      <td>-90.8484137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-14 03:30:00</td>\n",
       "      <td>Nooksack</td>\n",
       "      <td>WA</td>\n",
       "      <td>Light</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-05-14 03:35:00</td>\n",
       "      <td>0</td>\n",
       "      <td>-122.32366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-05-14 01:59:00</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Circle</td>\n",
       "      <td>1.5 seconds</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-14 01:59:05</td>\n",
       "      <td>0</td>\n",
       "      <td>-111.9400125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-05-14 00:20:00</td>\n",
       "      <td>Charleston (James Island)</td>\n",
       "      <td>SC</td>\n",
       "      <td>Fireball</td>\n",
       "      <td>5s</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-14 00:20:05</td>\n",
       "      <td>0</td>\n",
       "      <td>-79.9556455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-05-13 23:00:00</td>\n",
       "      <td>Golden</td>\n",
       "      <td>MS</td>\n",
       "      <td>Sphere</td>\n",
       "      <td>20 minutes</td>\n",
       "      <td>1200</td>\n",
       "      <td>2020-05-13 23:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>-91.0176357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-05-13 21:00:00</td>\n",
       "      <td>Shelton</td>\n",
       "      <td>CT</td>\n",
       "      <td>Light</td>\n",
       "      <td>1 hour</td>\n",
       "      <td>3600</td>\n",
       "      <td>2020-05-13 22:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.0931641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-05-13 03:37:00</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Light</td>\n",
       "      <td>7 seconds</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-05-13 03:37:07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-05-13 00:00:00</td>\n",
       "      <td>Gulf Mills</td>\n",
       "      <td>PA</td>\n",
       "      <td>Other</td>\n",
       "      <td>5 mins</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-05-13 00:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-05-12 12:05:00</td>\n",
       "      <td>Granby</td>\n",
       "      <td>CO</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>120</td>\n",
       "      <td>2020-05-12 12:07:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 start                       city state     shape  \\\n",
       "1  2020-05-14 21:40:00                   Wellborn    FL  Triangle   \n",
       "2  2020-05-14 20:45:00          Black River Falls    WI  Triangle   \n",
       "4  2020-05-14 03:30:00                   Nooksack    WA     Light   \n",
       "5  2020-05-14 01:59:00                      Tempe    AZ    Circle   \n",
       "6  2020-05-14 00:20:00  Charleston (James Island)    SC  Fireball   \n",
       "7  2020-05-13 23:00:00                     Golden    MS    Sphere   \n",
       "9  2020-05-13 21:00:00                    Shelton    CT     Light   \n",
       "12 2020-05-13 03:37:00                Springfield    NJ     Light   \n",
       "13 2020-05-13 00:00:00                 Gulf Mills    PA     Other   \n",
       "14 2020-05-12 12:05:00                     Granby    CO  Triangle   \n",
       "\n",
       "   duration_description  duration_secs                 end  lat           lon  \n",
       "1             5 minutes            300 2020-05-14 21:45:00    0   -85.8810774  \n",
       "2             2 minutes            120 2020-05-14 20:47:00    0   -90.8484137  \n",
       "4             5 minutes            300 2020-05-14 03:35:00    0    -122.32366  \n",
       "5           1.5 seconds              5 2020-05-14 01:59:05    0  -111.9400125  \n",
       "6                    5s              5 2020-05-14 00:20:05    0   -79.9556455  \n",
       "7            20 minutes           1200 2020-05-13 23:20:00    0   -91.0176357  \n",
       "9                1 hour           3600 2020-05-13 22:00:00    0   -73.0931641  \n",
       "12            7 seconds              7 2020-05-13 03:37:07    0             0  \n",
       "13               5 mins            300 2020-05-13 00:05:00    0             0  \n",
       "14            2 minutes            120 2020-05-12 12:07:00    0             0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://stackoverflow.com/questions/17098654/how-to-store-data-frame-using-pandas-python\n",
    "ufos_df.to_pickle(os.path.join(outputs,'ufos_df.pkl'))\n",
    "ufos_df = pd.read_pickle(os.path.join(outputs,'ufos_df.pkl'))\n",
    "ufos_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: dropna will drop any columns with None values, which is desirable\n",
    "ufos_df[[\"start\",\"end\",\"lon\",\"lat\",\"shape\"]].dropna().to_csv(os.path.join(outputs,'ufo_data.csv'),\n",
    "                                                             index=False, \n",
    "                                                             encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
